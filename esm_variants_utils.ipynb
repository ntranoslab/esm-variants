{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aUV6kgdrA5m6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "AAorder=['K','R','H','E','D','N','Q','T','S','C','G','A','V','L','I','M','P','Y','F','W']\n",
        "\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "##### INFERENCE\n",
        "def load_esm_model(model_name,device=0):\n",
        "  import torch\n",
        "  repr_layer = int(model_name.split('_')[1][1:])\n",
        "  model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", model_name)\n",
        "  batch_converter = alphabet.get_batch_converter() \n",
        "  return model.eval().to(device),alphabet,batch_converter,repr_layer\n",
        "\n",
        "def get_wt_LLR(input_df,device=0,silent=False): \n",
        "  # input: df.columns= id,\tgene,\tseq, length\n",
        "  # requires global model and batch_converter\n",
        "  # make sure input_df does not contain any nonstandard amino acids\n",
        "  AAorder=['K','R','H','E','D','N','Q','T','S','C','G','A','V','L','I','M','P','Y','F','W']\n",
        "  genes = input_df.id.values\n",
        "  LLRs=[];input_df_ids=[]\n",
        "  for gname in tqdm(genes,disable=silent):\n",
        "    seq_length=input_df[input_df.id==gname].length.values[0]\n",
        "    \n",
        "    if seq_length<=1022:\n",
        "      dt = [(gname+'_WT',input_df[input_df.id==gname].seq.values[0])]\n",
        "      batch_labels, batch_strs, batch_tokens = batch_converter(dt)\n",
        "      with torch.no_grad():\n",
        "        results_ = torch.log_softmax(model(batch_tokens.to(device), repr_layers=[33], return_contacts=False)['logits'],dim=-1)\n",
        "\n",
        "      WTlogits = pd.DataFrame(results_[0,:,:].cpu().numpy()[1:-1,:],columns=alphabet.all_toks,index=list(input_df[input_df.id==gname].seq.values[0])).T.iloc[4:24].loc[AAorder]\n",
        "      WTlogits.columns = [j.split('.')[0]+' '+str(i+1) for i,j in enumerate(WTlogits.columns)]\n",
        "      wt_norm=np.diag(WTlogits.loc[[i.split(' ')[0] for i in WTlogits.columns]])\n",
        "      LLR = WTlogits - wt_norm\n",
        "\n",
        "      LLRs += [LLR]\n",
        "      input_df_ids+=[gname]\n",
        "\n",
        "    else: ### tiling\n",
        "      long_seq = input_df[input_df.id==gname].seq.values[0]\n",
        "      ints,M,M_norm = get_intervals_and_weights(len(long_seq),min_overlap=512,max_len=1022,s=20)\n",
        "      \n",
        "      dt = []\n",
        "      for i,idx in enumerate(ints):\n",
        "        dt += [(gname+'_WT_'+str(i),''.join(list(np.array(list(long_seq))[idx])) )]\n",
        "\n",
        "      logit_parts = []\n",
        "      for dt_ in chunks(dt,20):\n",
        "        batch_labels, batch_strs, batch_tokens = batch_converter(dt_)\n",
        "        with torch.no_grad():\n",
        "          results_ = torch.log_softmax(model(batch_tokens.to(device), repr_layers=[33], return_contacts=False)['logits'],dim=-1)\n",
        "        for i in range(results_.shape[0]):\n",
        "          logit_parts += [results_[i,:,:].cpu().numpy()[1:-1,:]]\n",
        "          \n",
        "      logits_full = np.zeros((len(long_seq),33))\n",
        "      for i in range(len(ints)):\n",
        "        logit = np.zeros((len(long_seq),33))\n",
        "        logit[ints[i]] = logit_parts[i].copy()\n",
        "        logit = np.multiply(logit.T, M_norm[i,:]).T\n",
        "        logits_full+=logit\n",
        "        \n",
        "      WTlogits = pd.DataFrame(logits_full,columns=alphabet.all_toks,index=list(input_df[input_df.id==gname].seq.values[0])).T.iloc[4:24].loc[AAorder]\n",
        "      WTlogits.columns = [j.split('.')[0]+' '+str(i+1) for i,j in enumerate(WTlogits.columns)]\n",
        "      wt_norm=np.diag(WTlogits.loc[[i.split(' ')[0] for i in WTlogits.columns]])\n",
        "      LLR = WTlogits - wt_norm\n",
        "\n",
        "      LLRs += [LLR]\n",
        "      input_df_ids+=[gname]\n",
        "\n",
        "  return input_df_ids,LLRs\n",
        "\n",
        "def get_logits(seq,format=None,device=0):\n",
        "  data = [ (\"_\", seq),]\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "  with torch.no_grad():\n",
        "      logits = torch.log_softmax(model(batch_tokens, repr_layers=[33], return_contacts=False)[\"logits\"],dim=-1).cpu().numpy()\n",
        "  if format=='pandas':\n",
        "    WTlogits = pd.DataFrame(logits[0][1:-1,:],columns=alphabet.all_toks,index=list(seq)).T.iloc[4:24].loc[AAorder]\n",
        "    WTlogits.columns = [j.split('.')[0]+' '+str(i+1) for i,j in enumerate(WTlogits.columns)]\n",
        "    return WTlogits\n",
        "  else:\n",
        "    return logits[0][1:-1,:]\n",
        "\n",
        "def get_PLL(seq,reduce=np.sum,device=0):\n",
        "  s=get_logits(seq,device)\n",
        "  idx=[alphabet.tok_to_idx[i] for i in seq]\n",
        "  return reduce(np.diag(s[:,idx]))\n",
        "\n",
        "### MELTed CSV\n",
        "def meltLLR(LLR,savedir=None):\n",
        "  vars = LLR.melt(ignore_index=False)\n",
        "  vars['variant'] = [''.join(i.split(' '))+j for i,j in zip(vars['variable'],vars.index)]\n",
        "  vars['score'] = vars['value']\n",
        "  vars = vars.set_index('variant')\n",
        "  vars['pos'] = [int(i[1:-1]) for i in vars.index]\n",
        "  del vars['variable'],vars['value']\n",
        "  if savedir is not None:\n",
        "      vars.to_csv(savedir+'var_scores.csv')\n",
        "  return vars\n",
        "\n",
        "##################### TILING utils ###########################\n",
        "\n",
        "def chop(L,min_overlap=511,max_len=1022):\n",
        "  return L[max_len-min_overlap:-max_len+min_overlap]\n",
        "\n",
        "def intervals(L,min_overlap=511,max_len=1022,parts=None):\n",
        "  if parts is None: parts = []\n",
        "  #print('L:',len(L))\n",
        "  #print(len(parts))\n",
        "  if len(L)<=max_len:\n",
        "    if parts[-2][-1]-parts[-1][0]<min_overlap:\n",
        "      #print('DIFF:',parts[-2][-1]-parts[-1][0])\n",
        "      return parts+[np.arange(L[int(len(L)/2)]-int(max_len/2),L[int(len(L)/2)]+int(max_len/2)) ]\n",
        "    else:\n",
        "      return parts\n",
        "  else:\n",
        "    parts+=[L[:max_len],L[-max_len:]]\n",
        "    L=chop(L,min_overlap,max_len)\n",
        "    return intervals(L,min_overlap,max_len,parts=parts)\n",
        "\n",
        "def get_intervals_and_weights(seq_len,min_overlap=511,max_len=1022,s=16):\n",
        "  ints=intervals(np.arange(seq_len),min_overlap=min_overlap,max_len=max_len)\n",
        "  ## sort intervals\n",
        "  ints = [ints[i] for i in np.argsort([i[0] for i in ints])]\n",
        "\n",
        "  a=int(np.round(min_overlap/2))\n",
        "  t=np.arange(max_len)\n",
        "\n",
        "  f=np.ones(max_len)\n",
        "  f[:a] = 1 / (1 + np.exp(-(t[:a]-a/2)/s))\n",
        "  f[max_len-a:] = 1 / (1 + np.exp((t[:a]-a/2)/s))\n",
        "\n",
        "  f0=np.ones(max_len)\n",
        "  f0[max_len-a:] = 1 / (1 + np.exp((t[:a]-a/2)/s))\n",
        "\n",
        "  fn=np.ones(max_len)\n",
        "  fn[:a] = 1 / (1 + np.exp(-(t[:a]-a/2)/s))\n",
        "\n",
        "  filt=[f0]+[f for i in ints[1:-1]]+[fn]\n",
        "  M = np.zeros((len(ints),seq_len))\n",
        "  for k,i in enumerate(ints):\n",
        "    M[k,i] = filt[k]\n",
        "  M_norm = M/M.sum(0)\n",
        "  return (ints, M, M_norm)\n",
        "\n",
        "\n",
        "## PLLR score for indels\n",
        "def get_PLLR(wt_seq,mut_seq,start_pos,weighted=False):\n",
        "  fn=np.sum if not weighted else np.mean\n",
        "  if max(len(wt_seq),len(mut_seq))<=1022:\n",
        "    return  get_PLL(mut_seq,fn) - get_PLL(wt_seq,fn)\n",
        "  else:\n",
        "    wt_seq,mut_seq,start_pos = crop_indel(wt_seq,mut_seq,start_pos)\n",
        "    return  get_PLL(mut_seq,fn) - get_PLL(wt_seq,fn)\n",
        "\n",
        "def crop_indel(ref_seq,alt_seq,ref_start):\n",
        "  # Start pos: 1-indexed start position of variant\n",
        "  left_pos = ref_start-1\n",
        "  offset = len(ref_seq)-len(alt_seq)\n",
        "  start_pos = int(left_pos - 1022 / 2)\n",
        "  end_pos1 = int(left_pos + 1022 / 2) -min(start_pos,0)+ min(offset,0)\n",
        "  end_pos2 = int(left_pos + 1022 / 2) -min(start_pos,0)- max(offset,0)\n",
        "  if start_pos < 0: start_pos = 0 # Make sure the start position is not negative\n",
        "  if end_pos1 > len(ref_seq): end_pos1 = len(ref_seq) # Make sure the end positions are not beyond the end of the sequence\n",
        "  if end_pos2 > len(alt_seq): end_pos2 = len(alt_seq)\n",
        "  if start_pos>0 and max(end_pos2,end_pos1) - start_pos <1022: ## extend to the left if there's space\n",
        "            start_pos = max(0,max(end_pos2,end_pos1)-1022)\n",
        "\n",
        "  return ref_seq[start_pos:end_pos1],alt_seq[start_pos:end_pos2],start_pos-ref_start\n",
        "\n",
        "## stop gain variant score\n",
        "def get_minLLR(seq,stop_pos):\n",
        "  return min(get_wt_LLR(pd.DataFrame([('_','_',seq,len(seq))],columns=['id','gene','seq','length'] ),silent=True)[1][0].values[:,stop_pos:].reshape(-1))\n",
        "\n",
        "\n",
        "# ############### EXAMLE ##################\n",
        "# ## Load model\n",
        "# model,alphabet,batch_converter,repr_layer = load_esm_model(model_name='esm1b_t33_650M_UR50S',device='cuda')\n",
        "# ## Create a toy dataset\n",
        "# df_in = pd.DataFrame([('P1','gene1','FISHWISHFQRCHIPSTHATARECRISP',28),\n",
        "#                       ('P2','gene2','RAGEAGAINSTTHEMACHINE',21),\n",
        "#                       ('P3','gene3','SHIPSSAILASFISHSWIM',19),\n",
        "#                       ('P4','gene4','A'*1948,1948)], columns = ['id','gene','seq','length'])\n",
        "# ## Get LLRs\n",
        "# ids,LLRs = get_wt_LLR(df_in)\n",
        "# for i,LLR in zip(ids,LLRs):\n",
        "#   print(i,LLR.shape)\n",
        "# ## Get PLL\n",
        "# print(get_PLL(df_in.seq.values[0]))\n",
        "# ## indel: 14_IPS_delins_EESE (FISHWISHFQRCHIPSTHATARECRISP --> FISHWISHFQRCHEESETHATARECRISP)\n",
        "# get_PLLR('FISHWISHFQRCHIPSTHATARECRISP','FISHWISHFQRCHEESETHATARECRISP',14)\n",
        "# ## stop at position 17\n",
        "# get_minLLR(df_in.seq.values[0],17)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### example"
      ],
      "metadata": {
        "id": "ZShMiadyO-uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model\n",
        "model,alphabet,batch_converter,repr_layer = load_esm_model(model_name='esm1b_t33_650M_UR50S',device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clIbHRwrCYww",
        "outputId": "ba5bb3bd-5ea9-4688-db0d-218b4d6190df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_esm_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##create a toy dataset\n",
        "df_in = pd.DataFrame([('P1','gene1','FISHWISHFQRCHIPSTHATARECRISP',28),\n",
        "                      ('P2','gene2','RAGEAGAINSTTHEMACHINE',21),\n",
        "                      ('P3','gene3','SHIPSSAILASFISHSWIM',19),\n",
        "                      ('P4','gene4','A'*1948,1948)], columns = ['id','gene','seq','length'])"
      ],
      "metadata": {
        "id": "45N6RSGoPB-m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get LLRs\n",
        "ids,LLRs = get_wt_LLR(df_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noYpT2fbPEFc",
        "outputId": "028259ed-0858-4d13-93cd-fc50b75f4170"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,LLR in zip(ids,LLRs):\n",
        "  print(i,LLR.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ubRTY_4Pr2L",
        "outputId": "29722d7a-7cb9-409d-808c-99e9577a5210"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1 (20, 28)\n",
            "P2 (20, 21)\n",
            "P3 (20, 19)\n",
            "P4 (20, 1948)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_PLL(df_in.seq.values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk8M2c31PtmA",
        "outputId": "7d617123-4831-41df-a749-462fe200aa09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-16.311695"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indel 14_IPS_delins_EESE (FISHWISHFQRCHIPSTHATARECRISP --> FISHWISHFQRCHEESETHATARECRISP)\n",
        "get_PLLR('FISHWISHFQRCHIPSTHATARECRISP','FISHWISHFQRCHEESETHATARECRISP',14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP2KRAC6AaRS",
        "outputId": "a7064e66-d9de-49b4-9cfe-13a759737561"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0078125"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop at position 17\n",
        "get_minLLR(df_in.seq.values[0],17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydAO4K9HAOX2",
        "outputId": "f94a6537-c0b7-463e-c083-5051ad367348"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.1914926"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_WwmsxmIDZ5p"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}
